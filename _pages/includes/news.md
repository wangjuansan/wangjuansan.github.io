# 📢 News

<!-- 参考 https://huanwang.tech/ 的样式 -->

<!-- * <span style="font-size:12px;color:#FFFFFF;background-color:#007ec6;padding:1px 5px 1.5px 5px;">2025/02/24</span> **[Preprint]** We released [Humanoid-VLA](https://arxiv.org/abs/2502.14795), a novel framework that integrates language understanding, egocentric scene perception, and motion control, enabling universal humanoid control!

* <span style="font-size:12px;color:#FFFFFF;background-color:#007ec6;padding:1px 5px 1.5px 5px;">2024/03/13</span> **[ICME'24]** One paper ([DARA](https://arxiv.org/abs/2405.06217)) about parameter-efficient tuning for visual grounding got accepted for ICME 2024 (Oral). -->
